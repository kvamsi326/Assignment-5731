{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unt-iialab/INFO5731_Spring2020/blob/master/Assignments/INFO5731_Assignment_Three.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Three**\n",
        "\n",
        "In this assignment, you are required to conduct information extraction, semantic analysis based on **the dataset you collected from assignment two**. You may use scipy and numpy package in this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1: Understand N-gram**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(45 points). Write a python program to conduct N-gram analysis based on the dataset in your assignment two:\n",
        "\n",
        "(1) Count the frequency of all the N-grams (N=3).\n",
        "\n",
        "(2) Calculate the probabilities for all the bigrams in the dataset by using the fomular count(w2 w1) / count(w2). For example, count(really like) / count(really) = 1 / 3 = 0.33.\n",
        "\n",
        "(3) Extract all the **noun phrases** and calculate the relative probabilities of each review in terms of other reviews (abstracts, or tweets) by using the fomular frequency (noun phrase) / max frequency (noun phrase) on the whole dataset. Print out the result in a table with column name the all the noun phrases and row name as all the 100 reviews (abstracts, or tweets). \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuFPKhC0m1fd",
        "outputId": "29b2360e-74fa-4789-beec-99b93c2065ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'apt-get' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'apt' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'cp' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: selenium in c:\\users\\maganti\\anaconda3\\lib\\site-packages (4.4.3)\n",
            "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
            "Requirement already satisfied: trio~=0.17 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from selenium) (0.21.0)\n",
            "Requirement already satisfied: cffi>=1.14 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Requirement already satisfied: outcome in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: sniffio in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: idna in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
            "Requirement already satisfied: sortedcontainers in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: async-generator>=1.9 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
            "Requirement already satisfied: pycparser in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
            "Requirement already satisfied: wsproto>=0.14 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMkSsS_UE5LY"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('-headless')\n",
        "options.add_argument('-no-sandbox')\n",
        "options.add_argument('-disable-dev-shm-usage')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePlupRPLE5LY",
        "outputId": "243a9257-1038-46ce-e808-830c4cc73a14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting webdriver-manager\n",
            "  Downloading webdriver_manager-3.8.5-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: packaging in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from webdriver-manager) (21.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from webdriver-manager) (4.64.0)\n",
            "Requirement already satisfied: requests in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.27.1)\n",
            "Requirement already satisfied: python-dotenv in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.20.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from packaging->webdriver-manager) (3.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2021.10.8)\n",
            "Requirement already satisfied: colorama in c:\\users\\maganti\\anaconda3\\lib\\site-packages (from tqdm->webdriver-manager) (0.4.4)\n",
            "Installing collected packages: webdriver-manager\n",
            "Successfully installed webdriver-manager-3.8.5\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "!pip install webdriver-manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfI82XkqE5LZ",
        "outputId": "d471b1ef-fc1d-4ea9-9144-59d496434da1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\2160715986.py:4: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
            "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
          ]
        }
      ],
      "source": [
        "from selenium import webdriver\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "driver_chrome = webdriver.Chrome(ChromeDriverManager().install())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ERQSXQRE5LZ",
        "outputId": "b2a9c6e4-4757-4a62-8d1e-b5f801e4f770"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of data frame is 124\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Perfect in every aspect.</td>\n",
              "      <td>Truly a masterpiece, The Best Hollywood film o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A psychological study, rather than a superhero...</td>\n",
              "      <td>I have seen Joker yesterday at Venice an early...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Went for a second time to watch</td>\n",
              "      <td>I get why some people hate this . It's because...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>JUST AMAZING. How does this movie exist.</td>\n",
              "      <td>Let me start off by saying if Joaquin Phoneix ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Outstanding movie with a haunting performance ...</td>\n",
              "      <td>Every once in a while a movie comes, that trul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>Masterpiece *Movie Of the Year* Best Actor - J...</td>\n",
              "      <td>Wow I honestly gotta tell you, it's one of the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>The Joker is supposed to be a diabolical maste...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>Better if didn't saw</td>\n",
              "      <td>Disturbing. Just got out of the movie. My humo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>Why Todd Phillipps Made This Film</td>\n",
              "      <td>You will notice the far left journalists: the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>A total letdown ... a hybrid film bordering be...</td>\n",
              "      <td>Ugghhh how could I be so wrong in my assessmen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>124 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Title  \\\n",
              "0                             Perfect in every aspect.   \n",
              "1    A psychological study, rather than a superhero...   \n",
              "2                      Went for a second time to watch   \n",
              "3             JUST AMAZING. How does this movie exist.   \n",
              "4    Outstanding movie with a haunting performance ...   \n",
              "..                                                 ...   \n",
              "119  Masterpiece *Movie Of the Year* Best Actor - J...   \n",
              "120  The Joker is supposed to be a diabolical maste...   \n",
              "121                               Better if didn't saw   \n",
              "122                  Why Todd Phillipps Made This Film   \n",
              "123  A total letdown ... a hybrid film bordering be...   \n",
              "\n",
              "                                                Review  \n",
              "0    Truly a masterpiece, The Best Hollywood film o...  \n",
              "1    I have seen Joker yesterday at Venice an early...  \n",
              "2    I get why some people hate this . It's because...  \n",
              "3    Let me start off by saying if Joaquin Phoneix ...  \n",
              "4    Every once in a while a movie comes, that trul...  \n",
              "..                                                 ...  \n",
              "119  Wow I honestly gotta tell you, it's one of the...  \n",
              "120                                                     \n",
              "121  Disturbing. Just got out of the movie. My humo...  \n",
              "122  You will notice the far left journalists: the ...  \n",
              "123  Ugghhh how could I be so wrong in my assessmen...  \n",
              "\n",
              "[124 rows x 2 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from selenium.webdriver.support.ui import WebDriverWait as wait\n",
        "from selenium.webdriver.common.by import By\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "#driver = webdriver.Chrome(executable_path=\"C:\\chromedriver_win32\",options=options)\n",
        "link = 'https://www.imdb.com/title/tt7286456/reviews?ref_=tt_urv'\n",
        "title_array = []\n",
        "review_array = []\n",
        "driver_chrome.get(link)\n",
        "\n",
        "for num in range(4):\n",
        "  driver_chrome.find_element(By.CLASS_NAME, \"ipl-load-more__button\").click()\n",
        "  time.sleep(5)\n",
        "  listOfTitle = driver_chrome.find_elements(By.CLASS_NAME, \"title\")\n",
        "  listOfReviews = driver_chrome.find_elements(By.CLASS_NAME, \"text\")\n",
        "    \n",
        "    \n",
        "for ele, sub_ele in zip(listOfTitle, listOfReviews):\n",
        "      title_array.append((ele.text).replace('\\n',''))\n",
        "      review_array.append(sub_ele.text)\n",
        "    \n",
        "df = pd.DataFrame(list(zip(title_array, review_array)), columns =['Title', 'Review'])\n",
        "print(\"Length of data frame is {0}\".format(len(df)))\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMZttLEpE5La",
        "outputId": "47d82ff9-1c12-48b1-bc46-2d4257e0f251"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NH8w5xvxE5Lb"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import collections\n",
        "from nltk import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "words_sentence = []\n",
        "for sentence in df['Review']:\n",
        "    words_sentence.append(word_tokenize(sentence))\n",
        "    \n",
        "    \n",
        "aftercleaning = [x for x in words_sentence if x != []]\n",
        "iterations = list(itertools.chain.from_iterable(aftercleaning))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D38xBF9LE5Lb",
        "outputId": "ad72ac7f-d180-498a-8308-8d68d5ab1be1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FreqDist({('.', 'It', \"'s\"): 22, (',', 'it', \"'s\"): 19, ('.', 'This', 'is'): 14, (',', 'but', 'it'): 11, ('.', 'This', 'movie'): 11, ('one', 'of', 'the'): 10, ('it', \"'s\", 'a'): 10, ('.', 'It', 'is'): 10, ('this', 'movie', ','): 10, ('I', 'do', \"n't\"): 10, ...})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trigrams = nltk.trigrams(iterations)\n",
        "frequency_dist = nltk.FreqDist(trigrams)\n",
        "frequency_dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xw_96YFiE5Lb",
        "outputId": "7dd7cfe3-fc68-410f-fc34-ad1923d1271e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Truly', 'a'):1.0\n",
            "('a', 'masterpiece'):0.01702127659574468\n",
            "('masterpiece', ','):0.25\n",
            "(',', 'The'):0.004310344827586207\n",
            "('The', 'Best'):0.009615384615384616\n",
            "('Best', 'Hollywood'):0.16666666666666666\n",
            "('Hollywood', 'film'):0.16666666666666666\n",
            "('film', 'of'):0.02608695652173913\n",
            "('of', '2019'):0.013812154696132596\n",
            "('2019', ','):0.125\n",
            "(',', 'one'):0.0028735632183908046\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "bigrams = nltk.bigrams(iterations)\n",
        "frequency_dist = nltk.FreqDist(bigrams)\n",
        "bigrams_dict = dict(frequency_dist)\n",
        "count = 0\n",
        "\n",
        "for word in bigrams_dict:\n",
        "    if count > 10:\n",
        "        break\n",
        "    print( str(word) + ':' + str(bigrams_dict[word] / iterations.count(word[0])))\n",
        "    count=count+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cm6OisyE5Lc"
      },
      "outputs": [],
      "source": [
        "whole_dataset = ''\n",
        "index = []\n",
        "i = 1\n",
        "for line in df['Review']:\n",
        "    whole_dataset = whole_dataset + line\n",
        "    value = 'Review-' + str(i)\n",
        "    index.append(value)\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Abpcoc-E5Lc",
        "outputId": "288e538e-f521-448e-9805-91b156457a2c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>truly</th>\n",
              "      <th>hollywood</th>\n",
              "      <th>best</th>\n",
              "      <th>decade ...</th>\n",
              "      <th>best</th>\n",
              "      <th>comic book</th>\n",
              "      <th>real ife</th>\n",
              "      <th>direction</th>\n",
              "      <th>cinematography</th>\n",
              "      <th>disturbing</th>\n",
              "      <th>...</th>\n",
              "      <th>oscars</th>\n",
              "      <th>joker</th>\n",
              "      <th>joker</th>\n",
              "      <th>oscars</th>\n",
              "      <th>upon</th>\n",
              "      <th>time ...</th>\n",
              "      <th>hollywood</th>\n",
              "      <th>joker</th>\n",
              "      <th>oscar</th>\n",
              "      <th>joker</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Review-1</th>\n",
              "      <td>0.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Review-2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.038462</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.038462</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.125</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Review-3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Review-4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.038462</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.038462</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Review-5</th>\n",
              "      <td>0.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.038462</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.038462</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1607 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          truly  hollywood      best  decade ...      best  comic book  \\\n",
              "Review-1    0.1        NaN  0.000000         NaN  0.000000    0.076923   \n",
              "Review-2    0.0        NaN  0.038462         NaN  0.038462    0.000000   \n",
              "Review-3    0.0        NaN  0.000000         NaN  0.000000    0.000000   \n",
              "Review-4    0.0        NaN  0.038462         NaN  0.038462    0.000000   \n",
              "Review-5    0.1        NaN  0.038462         NaN  0.038462    0.000000   \n",
              "\n",
              "          real ife  direction  cinematography  disturbing  ...  oscars  joker  \\\n",
              "Review-1       1.0        0.0        0.000000    0.000000  ...     0.0  0.000   \n",
              "Review-2       0.0        0.0        0.058824    0.000000  ...     1.0  0.125   \n",
              "Review-3       0.0        0.0        0.058824    0.000000  ...     0.0  0.000   \n",
              "Review-4       0.0        0.0        0.000000    0.166667  ...     0.0  0.000   \n",
              "Review-5       0.0        0.0        0.000000    0.000000  ...     0.0  0.000   \n",
              "\n",
              "          joker  oscars  upon  time ...  hollywood  joker  oscar  joker  \n",
              "Review-1  0.000     0.0   0.0       NaN        NaN  0.000    0.0  0.000  \n",
              "Review-2  0.125     1.0   0.0       NaN        NaN  0.125    0.5  0.125  \n",
              "Review-3  0.000     0.0   0.0       NaN        NaN  0.000    0.0  0.000  \n",
              "Review-4  0.000     0.0   0.0       NaN        NaN  0.000    0.0  0.000  \n",
              "Review-5  0.000     0.0   0.0       NaN        NaN  0.000    0.0  0.000  \n",
              "\n",
              "[5 rows x 1607 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from textblob import TextBlob\n",
        "noun_phrases = []\n",
        "frequency = []\n",
        "\n",
        "for line in df['Review']:\n",
        "    blob = TextBlob(line)\n",
        "    for nouns in blob.noun_phrases:\n",
        "        noun_phrases.append(nouns)\n",
        "    \n",
        "    \n",
        "for word in noun_phrases:\n",
        "    noun_phrases_freq = []\n",
        "    for line in df['Review']:\n",
        "        try:\n",
        "            noun_phrases_freq.append(line.count(word) / whole_dataset.count(word))\n",
        "        except:\n",
        "            pass\n",
        "    frequency.append(noun_phrases_freq)\n",
        "    \n",
        "df_noun_phrases = pd.DataFrame(frequency).T\n",
        "df_noun_phrases.columns = list(noun_phrases)\n",
        "df_noun_phrases.index = index\n",
        "df_noun_phrases.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2: Undersand TF-IDF and Document representation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(20 points). Starting from the documents (all the reviews, or abstracts, or tweets) collected for assignment two, write a python program: \n",
        "\n",
        "(1) To build the **documents-terms weights (tf*idf) matrix bold text**.\n",
        "\n",
        "(2) To rank the documents with respect to query (design a query by yourself, for example, \"An Outstanding movie with a haunting performance and best character development\") by using **cosine similarity**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vATjQNTY8buA",
        "outputId": "9775f40f-9f4f-4263-caf4-6ca1809cd992"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n",
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n",
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n",
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n",
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n",
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n",
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n",
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n",
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n",
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n",
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n",
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n",
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n",
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n",
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n",
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n",
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n",
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n",
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n",
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n",
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n",
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n",
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n",
            "C:\\Users\\maganti\\AppData\\Local\\Temp\\ipykernel_27164\\3804204924.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>114</th>\n",
              "      <th>115</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>0.035297</td>\n",
              "      <td>0.020065</td>\n",
              "      <td>0.060693</td>\n",
              "      <td>0.033765</td>\n",
              "      <td>0.053239</td>\n",
              "      <td>0.054252</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.044658</td>\n",
              "      <td>0.035912</td>\n",
              "      <td>...</td>\n",
              "      <td>0.009926</td>\n",
              "      <td>0.04043</td>\n",
              "      <td>0.044997</td>\n",
              "      <td>0.075985</td>\n",
              "      <td>0.013377</td>\n",
              "      <td>0.018654</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.092222</td>\n",
              "      <td>0.019776</td>\n",
              "      <td>0.024792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sloppily</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>medal</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.024792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>role</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.024792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>superficial,</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 125 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          token         0         1         2         3         4         5  \\\n",
              "0                0.035297  0.020065  0.060693  0.033765  0.053239  0.054252   \n",
              "1      sloppily  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "2         medal  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "3          role  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "4  superficial,  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "\n",
              "     6         7         8  ...       114      115       116       117  \\\n",
              "0  0.0  0.044658  0.035912  ...  0.009926  0.04043  0.044997  0.075985   \n",
              "1  0.0  0.000000  0.000000  ...  0.000000  0.00000  0.000000  0.000000   \n",
              "2  0.0  0.000000  0.000000  ...  0.000000  0.00000  0.000000  0.000000   \n",
              "3  0.0  0.000000  0.000000  ...  0.000000  0.00000  0.000000  0.000000   \n",
              "4  0.0  0.000000  0.000000  ...  0.000000  0.00000  0.000000  0.000000   \n",
              "\n",
              "        118       119  120       121       122       123  \n",
              "0  0.013377  0.018654  0.0  0.092222  0.019776  0.024792  \n",
              "1  0.000000  0.000000  0.0  0.000000  0.000000  0.000000  \n",
              "2  0.000000  0.000000  0.0  0.000000  0.000000  0.024792  \n",
              "3  0.000000  0.000000  0.0  0.000000  0.000000  0.024792  \n",
              "4  0.000000  0.000000  0.0  0.000000  0.000000  0.000000  \n",
              "\n",
              "[5 rows x 125 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Write your code here\n",
        "\n",
        "import math\n",
        "\n",
        "\n",
        "def tf_idf_value(sentence,word):\n",
        "    size = len(sentence.split(\" \"))\n",
        "    tf_value = sentence.count(word)/size\n",
        "    idf_value = 0\n",
        "    if(tf_value!=0):\n",
        "        idf_value = math.log(size)/sentence.count(word)\n",
        "    else:\n",
        "        return 0;\n",
        "    return tf_value*idf_value\n",
        "\n",
        "review_sentences = df[\"Review\"].values.tolist()\n",
        "tokens_list = set([j for i in review_sentences for j in i.split(\" \")])\n",
        "\n",
        "tf_idf = pd.DataFrame(tokens_list,columns=[\"token\"])\n",
        "count = 0\n",
        "for i in review_sentences:\n",
        "    tf_idf[str(count)] = tf_idf[\"token\"].apply(lambda x : tf_idf_value(i,x))\n",
        "    count+=1\n",
        "\n",
        "tf_idf.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI8fr8RSE5Ld"
      },
      "source": [
        "# **Question 3: Create your own word embedding model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ntj7bYbWE5Ld"
      },
      "source": [
        "(20 points). Use the data you collected for assignment two to build a word embedding model: \n",
        "\n",
        "(1) Train a 300-dimension word embedding (it can be word2vec, glove, ulmfit, bert, or others).\n",
        "\n",
        "(2) Visualize the word embedding model you created.\n",
        "\n",
        "Reference: https://machinelearningmastery.com/develop-word-embeddings-python-gensim/\n",
        "\n",
        "Reference: https://jaketae.github.io/study/word2vec/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrZ4mgipE5Ld"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4G4CjlHE5Ld",
        "outputId": "30e10c87-6eae-471f-82c0-d7dfb8c89d02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['topics', 'of', 'semantic', 'structures', 'latent', 'produced', 'modeling', 'identifies', 'abstract', 'discovery', 'hidden', 'text', 'are', 'the', 'clusters', 'similar', 'words', 'It ', 'refers', 'to', 'statistical', 'algorithms', 'for', 'discovering', 'topic']\n",
            "[ 9.4563962e-05  3.0773187e-03 -6.8126465e-03 -1.3754654e-03\n",
            "  7.6685809e-03  7.3464084e-03 -3.6732983e-03  2.6427007e-03\n",
            " -8.3171297e-03  6.2054847e-03 -4.6373224e-03 -3.1641079e-03\n",
            "  9.3113566e-03  8.7338447e-04  7.4907015e-03 -6.0740639e-03\n",
            "  5.1605059e-03  9.9228211e-03 -8.4573915e-03 -5.1356913e-03\n",
            " -7.0648384e-03 -4.8626517e-03 -3.7785650e-03 -8.5362010e-03\n",
            "  7.9556061e-03 -4.8439382e-03  8.4236125e-03  5.2625705e-03\n",
            " -6.5500261e-03  3.9578700e-03  5.4701497e-03 -7.4265362e-03\n",
            " -7.4057197e-03 -2.4752307e-03 -8.6257271e-03 -1.5815735e-03\n",
            " -4.0343284e-04  3.2996845e-03  1.4418793e-03 -8.8142155e-04\n",
            " -5.5940580e-03  1.7303658e-03 -8.9737179e-04  6.7936899e-03\n",
            "  3.9735888e-03  4.5294715e-03  1.4343048e-03 -2.6998566e-03\n",
            " -4.3668128e-03 -1.0320758e-03  1.4370275e-03 -2.6460099e-03\n",
            " -7.0737838e-03 -7.8053069e-03 -9.1217877e-03 -5.9351707e-03\n",
            " -1.8474245e-03 -4.3238713e-03 -6.4606713e-03 -3.7173224e-03\n",
            "  4.2891572e-03 -3.7390448e-03  8.3781742e-03  1.5339922e-03\n",
            " -7.2423196e-03  9.4337985e-03  7.6312111e-03  5.4932809e-03\n",
            " -6.8488456e-03  5.8226776e-03  4.0090918e-03  5.1853680e-03\n",
            "  4.2559002e-03  1.9397545e-03 -3.1701636e-03  8.3538434e-03\n",
            "  9.6121784e-03  3.7926030e-03 -2.8369951e-03  7.1263312e-06\n",
            "  1.2188172e-03 -8.4583256e-03 -8.2239462e-03 -2.3101569e-04\n",
            "  1.2372875e-03 -5.7433820e-03 -4.7252751e-03 -7.3460746e-03\n",
            "  8.3286138e-03  1.2129784e-04 -4.5093987e-03  5.7017040e-03\n",
            "  9.1800140e-03 -4.0998720e-03  7.9646800e-03  5.3754328e-03\n",
            "  5.8791232e-03  5.1259040e-04  8.2130842e-03 -7.0190406e-03]\n"
          ]
        }
      ],
      "source": [
        "sentences = [['topic', 'modeling', 'identifies', 'abstract', 'topics'],\n",
        "             ['discovery', 'of', 'hidden', 'semantic', 'text', 'structures'],\n",
        "            ['topics', 'produced', 'are', 'clusters', 'of', 'similar', 'words'],\n",
        "            ['It ', 'refers', 'to', 'statistical', 'algorithms', 'for', 'discovering', 'the', 'latent', 'semantic', 'structures']]\n",
        "\n",
        "model = Word2Vec(sentences, min_count=1)\n",
        "\n",
        "words = list(model.wv.index_to_key)\n",
        "print(words)\n",
        "print(model.wv['semantic'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 4: Create your own training and evaluation data for sentiment analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(15 points). **You dodn't need to write program for this question!** Read each review (abstract or tweet) you collected in detail, and annotate each review with a sentiment (positive, negative, or neutral). Save the annotated dataset into a csv file with three columns (first column: document_id, clean_text, sentiment), upload the csv file to GitHub and submit the file link blew. This datset will be used for assignment four: sentiment analysis and text classification. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfvMKJjIXS5G"
      },
      "outputs": [],
      "source": [
        "# The GitHub link of your final csv file\n",
        "\n",
        "\n",
        "\n",
        "# Link: https://github.com/kvamsi326/Assignment-5731/blob/main/11554721%20Assignment%203.xlsx\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}